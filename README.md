# ğŸ¤ Real-Time Voice Emotion Detection

## ğŸ“Œ Overview

This project implements a real-time voice emotion detection system using deep learning. It captures speech from a microphone, processes audio signals, and predicts the speakerâ€™s emotional state using a pre-trained HuBERT model. The system runs offline and provides interactive results through a graphical interface.

It demonstrates the practical use of speech emotion recognition in humanâ€“computer interaction and intelligent user analysis.

---

## ğŸš€ Features

* Real-time microphone audio recording
* Deep learningâ€“based emotion classification
* Offline model loading (no internet required)
* Silence detection to avoid false predictions
* GUI-based interaction
* Displays emotion label and confidence score

---

## ğŸ§  Technologies Used

* Python
* PyTorch
* Hugging Face Transformers
* HuBERT Speech Model
* NumPy
* SoundDevice
* Tkinter / Flask (UI integration)

---

## ğŸ“‚ Project Structure

```
project-folder/
â”‚
â”œâ”€â”€ static/                    # Frontend assets
â”œâ”€â”€ templates/                 # HTML templates
â”‚
â”œâ”€â”€ app.py                     # Flask application
â”œâ”€â”€ database.db                # SQLite database
â”œâ”€â”€ emotion.py                 # Voice emotion detection module
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ hubert_emotion/        # Pretrained HuBERT model files
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸ¤– Model

HuBERT Speech Emotion Recognition Model:
[https://huggingface.co/xmj2002/hubert-base-ch-speech-emotion-recognition](https://huggingface.co/xmj2002/hubert-base-ch-speech-emotion-recognition)

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone Repository

```
git clone <repository-url>
cd <project-folder>
```

### 2ï¸âƒ£ Install Dependencies

```
pip install -r requirements.txt
```

Or manually:

```
pip install torch transformers sounddevice numpy
```

---

## â–¶ï¸ Usage

Run the application:

```
python app.py
```

### Controls

* **Start** â†’ Begins listening and emotion detection
* **Stop** â†’ Stops detection

Detected emotion and confidence will appear on the interface.

---

## ğŸ¯ Supported Emotions

* Neutral
* Angry
* Sad
* Confident (mapped from happy class)
* Silence detection

---

## ğŸ” How It Works

1. Records 6-second audio clips at 16kHz
2. Checks for silence using amplitude threshold
3. Extracts features using Wav2Vec2 extractor
4. HuBERT model predicts emotion class
5. Displays result with confidence score

---

## ğŸ“ˆ Applications

* Smart assistants
* Mental health monitoring
* Customer sentiment analysis
* Humanâ€“computer interaction research
* Interview assessment tools

---

## âš ï¸ Limitations

* Limited emotion categories
* Performance depends on audio quality
* Sensitive to noisy environments
* Uses fixed recording duration

---

## ğŸ”® Future Improvements

* Expand emotion classes
* Real-time streaming inference
* Noise filtering & preprocessing
* Prediction history storage
* Web/mobile deployment

---

## ğŸ‘¤ Author

**Chandru â€” AI/ML Developer**

---

## ğŸ“œ License

This project is intended for academic and educational purposes.
